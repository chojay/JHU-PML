---
title: "Practical Machine Learning Course Project"
author: "Jay Cho"
date: "March 11, 2017"
output: html_document
---

#Libraries used
```{r, message=FALSE}
library(tidyverse)
library(caret)
```

# Data Loading & Data Exploratation

```{r}
#Load Training Data
train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")

#Load Test Data
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")

```

# Data Pre-Processing: Removing non-zero variance columns

The next step would be is to pre-process data further. I'll first remove near zero variance columns using [nzv function from the caret package](https://topepo.github.io/caret/pre-processing.html). 
```{r}
nzv <- nearZeroVar(train, saveMetrics = TRUE) #Identifying 
sum(nzv$nzv) #Checking how many near zero variance columns exist

train <- train[,nzv$nzv == FALSE] #Keeping the columns that are non near-zero variances for the train set
test <- test[,nzv$nzv == FALSE] #Keeping the columns that are non near-zero variances for the test set

# head(train); head(test)
```
# Removing NA columns
Looks like there are many columns with 'NA's. Keeping them will interfere with our model so we'll remove those before fitting a model:
```{r}
col_to_remove <- names(train)[colSums(is.na(train)>0) > 0] #Find na values, run a column sum, change to logical values for those with total sum greater than 0

train <- train[, !colnames(train) %in% col_to_remove] #Removing columns with NA values
```


# Fitting a model : Random Forest
We've learned in the class that [Random Forest (RF)](https://en.wikipedia.org/wiki/Random_forest) is one of the more powerful classification technique owing to its emsembled outcome. As such I will try to fit the random forest model first:

```{r}
#Will fit a RF model with 10 cross-validation. Let's create a control parameter:
control_param <- trainControl(method = "cv", number = 4)

#Fitting a random forest model:
rf_model <- train(classe ~ ., data = train, method = "rf", trControl = control_param)

#Model Evaluation
rf_model
confusionMatrix(rf_model)
```
Final model has much less than 1% in-sample error rate, so we can conclude the random forest model should be good enough to be tested on the test set. Let's predict on test-set. 

##Expected out of sample rate:
If we assume the model will predict at its best accuracy, we can estimate the out-of-sample error percent as: (1 - max accuracy) * 100
```{r}
(1-max(rf_model$results$Accuracy)) * 100 
```

# Prediction on the test set  
```{r}
test <- test[, !colnames(test) %in% col_to_remove] #Removing the same NA columns before fitting the RF model
test_prediction <- predict(rf_model, newdata = test)
test_prediction
```







