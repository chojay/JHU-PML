getwd()
train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
train
str(train)
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", row.names = FALSE)
train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", row.names = FALSE)
?read.csv
train <- read.table("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", row.names = FALSE)
test <- read.table("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
test <- tibble("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
test <- as_tibble("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
library(tidyverse)
library(caret)
test <- as.tibble("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
test <- as_tibble("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
test
test <- read.csv2("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
train <- read.table("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
train <- read.table("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
train <- read.table("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
test
test
test
test
test
test
unname(test)
test
library(tidyverse)
library(caret)
#Load Training Data
train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv") %>%
select(-X) #Remove row index
#Load Test Data
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv") %>%
select(-X) #Remove row index
test
?lubraidate
lubridate
?lubridate
test %>%
mutate(cvtd_timestamp = lubridate::as_datetime(cvtd_timestamp))
test
test
test %>%
mutate(cvtd_timestamp = lubridate::mdy_hm(cvtd_timestamp, )))
test %>%
mutate(cvtd_timestamp = lubridate::mdy_hm(cvtd_timestamp)))
test %>%
mutate(cvtd_timestamp = lubridate::mdy_hm(cvtd_timestamp))
test
test %>%
mutate(cvtd_timestamp = lubridate::dmy_hm(cvtd_timestamp))
train
test <- test %>%
mutate(cvtd_timestamp = lubridate::dmy_hm(cvtd_timestamp))
train <- train %>% mutate(cvtd_timestamp = lubridate::dmy_hm(cvtd_timestamp))
train
train$classe
table(train$classe)
library(caret)
str(test)
train <- subset(train, select = -c(user_name))
valid_index <- createDataPartition(train$classe, p = 0.7, list = FALSE)
inValid <- createDataPartition(train$classe, p = 0.7, list = FALSE)
inTrain <- createDataPartition(train$classe, p = 0.7, list = FALSE)
inTrain <- createDataPartition(train$classe, p = 0.7, list = FALSE)
train_data <- train[intran,]
train_data <- train[inTrain,]
valid_data <- tran[-inTrain,]
valid_data <- train[-inTrain,]
library(caret)
train <- subset(train, select = -c(user_name))
train
library(caret)
train
# train <- subset(train, select = -c(user_name))
inTrain <- createDataPartition(train$classe, p = 0.7, list = FALSE)
train_data <- train[inTrain,]
valid_data <- train[-inTrain,]
mod1 <- train(classe ~ . , method = "glm", data=train_data)
library(caret)
train
# train <- subset(train, select = -c(user_name))
inTrain <- createDataPartition(train$classe, p = 0.7, list = FALSE)
train_data <- train[inTrain,]
valid_data <- train[-inTrain,]
mod1 <- train(classe ~ . , method = "glm", data=train_data, na.action = na.pass)
mod2 <- train(classe ~ . , method = "rf", data=train_data, trControl = trainControl(method = "cv"), number = 10, na.action = na.pass)
train_data
summary(train_data)
mod2 <- train(classe ~ . , method = "rf", data=train_data, trControl = trainControl(method = "cv"), number = 3, na.action = na.exclude)
pred2 <- predict(mod2,train_data)
plot(pred2)
mod1 <- train(classe ~ . , method = "glm", data=train_data, na.action = na.exclude)
rf_model <- train(classe ~ . , method = "rf", data=train, trControl = trainControl(method = "cv"), number = 4, na.action = na.exclude)
library(tidyverse)
library(caret)
#Load Training Data
train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv") %>%
select(-X) #Remove row index
#Load Test Data
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv") %>%
select(-X) #Remove row index
test <- test %>%
mutate(cvtd_timestamp = lubridate::dmy_hm(cvtd_timestamp))
train <- train %>% mutate(cvtd_timestamp = lubridate::dmy_hm(cvtd_timestamp))
#Need to change timestamp to month date year
train
train$classe
library(caret)
train
# train <- subset(train, select = -c(user_name))
inTrain <- createDataPartition(train$classe, p = 0.7, list = FALSE)
train_data <- train[inTrain,]
valid_data <- train[-inTrain,]
# mod1 <- train(classe ~ . , method = "glm", data=train_data, na.action = na.exclude)
# mod2 <- train(classe ~ . , method = "rf", data=train_data, trControl = trainControl(method = "cv"), number = 3, na.action = na.exclude)
#
# # pred1 <- predict(mod1,train_data)
# pred2 <- predict(mod2,train_data)
#
# # predDF <- data.frame(pred1,pred2,train$classe)
#
# # combModFit <- train(classe ~ ., method = "gam", data=predDF)
#
# combPred <- predict(combModFit, predDF)
#
#
# plot(pred2)
rf_model <- train(classe ~ . , method = "rf", data=train, trControl = trainControl(method = "cv"), number = 4, na.action = na.exclude)
library(tidyverse)
library(caret)
#Load Training Data
train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv") %>%
select(-X) #Remove row index
#Load Test Data
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv") %>%
select(-X) #Remove row index
test <- test %>%
mutate(cvtd_timestamp = lubridate::dmy_hm(cvtd_timestamp))
train <- train %>% mutate(cvtd_timestamp = lubridate::dmy_hm(cvtd_timestamp))
#Need to change timestamp to month date year
train
train$classe
library(caret)
train
# train <- subset(train, select = -c(user_name))
inTrain <- createDataPartition(train$classe, p = 0.7, list = FALSE)
train_data <- train[inTrain,]
valid_data <- train[-inTrain,]
# mod1 <- train(classe ~ . , method = "glm", data=train_data, na.action = na.exclude)
mod2 <- train(classe ~ . , method = "rf", data=train_data, trControl = trainControl(method = "cv"), number = 3, na.action = na.exclude)
library(caret)
train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
head(train); head(test)
test$new_window
head(train); head(test)
unique(train$new_window) #Exploring what the unique values are under 'new_window' column
train$new_window #Exploring what the unique values are under 'new_window' column
table(train$new_window) #Exploring what the unique values are under 'new_window' column
train <- train[,-(1:5)]
test <- test[,-(1:5)]
nzv <- nearZeroVar(training, saveMetrics = TRUE)
nzv <- nearZeroVar(train, saveMetrics = TRUE)
nzv$nzv
sum(nzv$nzv)
train <- train[,nzv$nzv == FALSE] #Keeping the columns that are non near-zero variances
test <- test[,nzv$nzv == FALSE] #Keeping the columns that are non near-zero variances
#Will fit a RF model with 10 cross-validation. Let's create a control parameter:
control_param <- trainControl(method = "cv", number = 8)
rf_model <- train(classe ~ ., data = train, method = "rf", trControl = control_param)
#Will fit a RF model with 10 cross-validation. Let's create a control parameter:
control_param <- trainControl(method = "cv", number = 10)
rf_model <- train(classe ~ ., data = train, method = "rf", trControl = control_param, na.action = na.exclude))
rf_model <- train(classe ~ ., data = train, method = "rf", trControl = control_param, na.action = na.exclude)
control_param <- trainControl(method = "cv", number = 10)
rf_model <- train(classe ~ ., data = train, method = "rf", trControl = control_param, na.action = na.exclude)
confusionMatrix(rf_model)
rf_model
rf_model_naomit <- train(classe ~ ., data = train_naomit, method = "rf", trControl = control_param)
train_naomit <- na.omit(train)
rf_model_naomit <- train(classe ~ ., data = train_naomit, method = "rf", trControl = control_param)
rf_model_naomit
train_naomit
preProcValues <- preProcess(train, method = c("center", "scale"))
predict(preProcValues,train)
preProcValues <- preProcess(train, method = c("center", "scale"), na.remove = TRUE)
predict(preProcValues,train)
train_scaled <- predict(preProcValues,train)
rf_model_scaled <- train(classe ~ ., data = train_scaled, method = "rf", trControl = control_param) #Running the same model
preProcValues <- preProcess(train, method = c("center", "scale"), na.action = na.omit)
train_scaled <- predict(preProcValues,train)
rf_model_scaled <- train(classe ~ ., data = train_scaled, method = "rf", trControl = control_param) #Running the same model
rf_model_scaled <- train(classe ~ ., data = train_scaled, method = "rf", trControl = control_param, na.action = na.omit) #Running the same model
rf_model_scaled
library(tidyverse)
library(caret)
#Load Training Data
train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
#Load Test Data
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
#Checking the format of the traiing and test data:
head(train); head(test)
table(train$new_window) #Exploring what the unique values are under 'new_window' column
dim(train); dim(test) #Checking dimensions before subsetting
train <- train[,-(1)]
test <- test[,-(1)]
dim(train); dim(test) #Checking dimensinos after subsetting. We have 5 less columns in each dataframe so we subsetted successfully.
nzv <- nearZeroVar(train, saveMetrics = TRUE) #Identifying
sum(nzv$nzv) #Checking how many near zero variance columns exist
train <- train[,nzv$nzv == FALSE] #Keeping the columns that are non near-zero variances for the train set
test <- test[,nzv$nzv == FALSE] #Keeping the columns that are non near-zero variances for the test set
#Will fit a RF model with 10 cross-validation. Let's create a control parameter:
control_param <- trainControl(method = "cv", number = 10)
rf_model <- train(classe ~ ., data = train, method = "rf", trControl = control_param, na.action = na.exclude)
rf_model
train_naomit <- na.omit(train) #Keeping only the full dataset
rf_model_naomit <- train(classe ~ ., data = train_naomit, method = "rf", trControl = control_param) #Running the same model again
rf_model_naomit
preProcValues <- preProcess(train, method = c("center", "scale"), na.action = na.omit)
train_scaled <- predict(preProcValues,train)
rf_model_scaled <- train(classe ~ ., data = train_scaled, method = "rf", trControl = control_param, na.action = na.omit) #Running the same model
rf_model_scaled
control_param <- trainControl(method = "cv", number = 4)
rf_model <- train(classe ~ ., data = train, method = "rf", trControl = control_param, na.action = na.exclude)
rf_model
rf_model <- train(classe ~ ., data = train, method = "rf", trControl = control_param, na.action = na.exclude, ntree = 500)
rf_model
control_param <- trainControl(method = "cv", number = 4, mtry = 10)
control_param <- trainControl(method = "cv", number = 4)
control_param <- trainControl(method = "cv", number = 4)
rf_model <- train(classe ~ ., data = train, method = "rf", trControl = control_param, na.action = na.exclude, ntree = 500)
rf_model
dim(train); dim(test) #Checking dimensions before subsetting
train <- train[,-(1)]
test <- test[,-(1)]
dim(train); dim(test) #Checking dimensinos after subsetting. We have 5 less columns in each dataframe so we subsetted successfully.
nzv <- nearZeroVar(train, saveMetrics = TRUE) #Identifying
sum(nzv$nzv) #Checking how many near zero variance columns exist
train <- train[,nzv$nzv == FALSE] #Keeping the columns that are non near-zero variances for the train set
test <- test[,nzv$nzv == FALSE] #Keeping the columns that are non near-zero variances for the test set
train
control_param <- trainControl(method = "cv", number = 4)
rf_model <- train(classe ~ ., data = train, method = "rf", trControl = control_param)
View(train)
nzv <- nearZeroVar(train, saveMetrics = TRUE) #Identifying
sum(nzv$nzv) #Checking how many near zero variance columns exist
train <- train[,nzv$nzv == FALSE] #Keeping the columns that are non near-zero variances for the train set
test <- test[,nzv$nzv == FALSE] #Keeping the columns that are non near-zero variances for the test set
head(train); head(test)
is.na(train)
is.na(train)>0
colSums(is.na(train)>0)
is.na(train)>0
colSums(is.na(train)>0)
sum(colSums(is.na(train)>0))
colSums(is.na(train)>0)
names(train)
colSums(is.na(train)>0)
names(train)[colSums(is.na(train)>0)]
colnames(train)[colSums(is.na(train)>0)]
colSums(is.na(train)>0) > 0
names(train)[colSums(is.na(train)>0) > 0]
train %>% select(-col_to_remove) #Removing columns with NA values
col_to_remove <- names(train)[colSums(is.na(train)>0) > 0] #Find na values, run a column sum, change to logical values for those with total sum greater than 0
train %>% select(-col_to_remove) #Removing columns with NA values
col_to_remove
str(col_to_remove)
unlist(col_to_remove)
train %>% select_(-col_to_remove) #Removing columns with NA values
subset(train, select = -col_to_remove) #Removing columns with NA values
col_to_remove <- names(train)[colSums(is.na(train)>0) > 0] #Find na values, run a column sum, change to logical values for those with total sum greater than 0
col_to_remove
select_(train, .dots = -col_to_remove) #Removing columns with NA values
train
select(train, col_to_remove)
col_to_remove <- names(train)[colSums(is.na(train)>0) > 0] #Find na values, run a column sum, change to logical values for those with total sum greater than 0
col_to_remove
train[,-col_to_remove]
colnames(col_to_remove)
colnames(train)
colnames(train) == col_to_remove
colnames(train) %in% col_to_remove
train[,colnames(train) %in% col_to_remove]
train[,!colnames(train) %in% col_to_remove]
train <- train[, !colnames(train) %in% col_to_remove]
#Will fit a RF model with 10 cross-validation. Let's create a control parameter:
control_param <- trainControl(method = "cv", number = 4)
rf_model <- train(classe ~ ., data = train, method = "rf", trControl = control_param)
confusionMatrix(rf_model)
rf_model
rf_model$finalModel
confusionMatrix(rf_model$finalModel)
#Will fit a RF model with 10 cross-validation. Let's create a control parameter:
control_param <- trainControl(method = "cv", number = 4)
#Fitting a random forest model:
rf_model <- train(classe ~ ., data = train, method = "rf", trControl = control_param)
confusionMatrix(rf_model)
test <- test[, !colnames(test) %in% col_to_remove] #Removing the same NA columns before fitting the RF model
predict(rf_model, newdata = test)
test_prediction <- predict(rf_model, newdata = test)
confusionMatrix(test_prediction)
test_prediction <- predict(rf_model, newdata = test)
test_prediction
rf_model$results
max(rf_model$results)
max(rf_model$results$Accuracy)
1-max(rf_model$results$Accuracy)
1-max(rf_model$results$Accuracy)
1-max(rf_model$results$Accuracy) * 100
(1-max(rf_model$results$Accuracy)) * 100
